{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTgBGsgjDbC0"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from datasets import load_dataset\n",
        "import cassio\n"
      ],
      "metadata": {
        "id": "RPTd5oUtXvks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQtt0wg5Ysg1",
        "outputId": "7f2fd1de-1011-4612-8993-973ec9272b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "Qq3EDqpxYvlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = 'ASTRA_DB_APPLICATION_TOKEN'\n",
        "ASTRA_DB_ID = 'ASTRA_DB_ID'\n",
        "\n",
        "OPENAI_API_KEY = 'OPENAI_API_KEY'"
      ],
      "metadata": {
        "id": "C-renQbuY-o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('file.pdf')"
      ],
      "metadata": {
        "id": "zRUS5UHda4R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "  content = page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ],
      "metadata": {
        "id": "w4eCMLOebtBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "id": "7BUNeAugb09L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "b5ea190b-c295-4196-8a1b-336643b0e5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1 \\n UNIT -3: Parameter Norm Penalties, Data set augmentation, Noise Robustness, Early \\nstopping, Bagging and other Ensemble methods, Dropouts.  \\nI. Parameter Norm Penalties: Parameter norm penalties, also known as regularization \\ntechniques, are methods used to prevent overfitting and improve the generalization \\nperformance of machine learning models. These penalties add a term to the loss \\nfunction during training that encourages the model\\'s weights to stay small or have a \\nsparse distribution. By constraining the weights, parameter norm penalties help \\nprevent the model from fitting the noise in the training data and promote more robust \\nand simpler solutions. Examples of parameter norm penalties include L1 \\nregularization (Lasso) and L2 regularization (Ridge regressi on). \\nParameter norm penalties, such as L1 and L2 regularization, are techniques used in machine \\nlearning to prevent overfitting and improve the performance of models.  \\nOverfitting occurs when a model becomes too specialized to the training data and perform s \\npoorly on new, unseen data.  \\nParameter norm penalties add an extra term to the loss function during training, encouraging \\nthe model\\'s weights to stay small or have a sparse distribution.  \\nBy constraining the weights, these penalties prevent the model from fitting noise in the \\ntraining data, leading to more robust and reliable solutions.  \\nL1 regularization, also known as Lasso regularization, adds the absolute values of the weights \\nto the loss function. This encourages the model to have sparse weights, meanin g it will \\nprioritize some features while disregarding others.  \\nL2 regularization, also called Ridge regression, adds the squared values of the weights to the \\nloss function. This penalty prefers small weights and discourages the model from relying \\nheavily on  a few features.  \\nBoth L1 and L2 regularization techniques help simplify the model, promoting solutions that \\nare less prone to overfitting and have better generalization performance on unseen data.  \\nIn summary, parameter norm penalties are regularization tec hniques that control the size and \\ndistribution of a model\\'s weights, preventing overfitting and improving the model\\'s ability to \\ngeneralize to new data.  2 \\n II. Data Set Augmentation:  Data set augmentation is a technique used  to increase the \\nsize and diversity of the training data by applying various transformations or \\nperturbations to the existing data.  This technique can help improve the generalization \\nperformance of models, especially in situations where the available training data is \\nlimited. Data set augmen tation methods include rotation, translation, scaling, flipping, \\nadding noise, and introducing small variations to the data samples.  By augmenting the \\ndata set, the model becomes more robust to variations and can learn more generalized \\npatterns.  \\nData set augmentation is a method used to make training data larger and more diverse.  \\nBy applying different transformations or changes to the existing data, data set augmentation \\ncan improve the performance of models, especially when there is limited training data \\navailable.  \\nVarious transformations can be used for data set augmentation, such as rotating, translating, \\nscaling, flipping, adding noise, or making small variations to the data samples.  \\nWhen we augment the data set, we introduce more variations and increas e the robustness of \\nthe model to different patterns and scenarios.  \\nFor example, by rotating an image slightly or flipping it horizontally, we can create new \\nsamples that still represent the same object or concept.  \\nAdding noise to the data, such as random p ixel variations, can simulate real -world scenarios \\nand make the model more resilient to noise in the input data.  \\nBy augmenting the data set, the model can learn from a broader range of examples and \\ngeneralize better to unseen data.  \\nIn summary, data set aug mentation involves applying transformations or perturbations to \\nexisting data to create a larger and more diverse training set. This helps the model become \\nmore robust and capable of generalizing to different patterns and variations.  \\nIII. Noise Robustness:  Nois e robustness refers to the ability of a machine learning model \\nto handle noisy or corrupted input data . In real -world scenarios, data can be corrupted \\nby various sources of noise, such as sensor noise, measurement errors, or \\nperturbations. Models that are robust to noise can still make accurate predictions or 3 \\n classifications despite the presence of noisy data. Techniques for improving noise \\nrobustness include data preprocessing (e.g., denoising algorithms), feature selection or \\nextraction, robust statistica l estimators, and regularized models.  \\nNoise robustness in machine learning refers to a model\\'s capability to handle input data that is \\ncorrupted or contains noise. In real -world situations, data can be affected by different sources \\nof noise, like sensor inaccuracies, measurement errors, or disturbances in the environment.  \\nA noise -robust model can still provide accurate predictions or classifications even when faced \\nwith such noisy data. This is important because noise can distort the true underlying patterns \\nin the data, making it challenging for models to extract meaningful information.  \\nThere are several techniques that can be employed to enhance noise robustness:  \\n1. Data Preprocessing:  One approach is to apply denoising algorithms or filters to \\nremove or reduce noise from the input data before feeding it to the model. These \\nalgorithms can help in separating the noise from the actual signal, enhancing the \\nmodel\\'s ability to make accurate  predictions.  \\n2. Feature Selection or Extraction:  Another technique involves selecting or extracting \\nfeatures that are less sensitive to noise. By focusing on robust features that capture \\nessential patterns in the data while being less affected by noise, the model can \\nimprove its noise robustness.  \\n3. Robust Statistical Estimators:  Instead of relying on traditional statistical estimators \\nthat assume data follows a specific distribution, robust statistical estimators are \\ndesigned to be more resistant to outliers an d noisy data. These estimators provide \\nmore reliable estimates and can be utilized in building noise -robust models.  \\n4. Regularized Models:  Regularization techniques, such as L1 or L2 regularization, can \\nalso contribute to noise robustness. By adding penalties  to the model\\'s loss function, \\nregularization encourages simpler and more robust solutions that are less affected by \\nnoise in the training data.  \\nBy employing these techniques, noise robustness can be improved, enabling machine \\nlearning models to handle noi sy or corrupted data more effectively. This ensures that the \\nmodels can still make accurate predictions or classifications, even in real -world scenarios \\nwhere noise is present.  4 \\n IV. Early Stopping:  Early stopping is a regularization technique used during the t raining \\nof neural networks to prevent overfitting.  It involves monitoring the model\\'s \\nperformance on a validation set during training and stopping the training process \\nwhen the performance on the validation set starts to deteriorate. By stopping the \\ntraini ng early, the model avoids further optimization that may lead to overfitting the \\ntraining data. Early stopping helps find a balance between training the model enough \\nto capture meaningful patterns and preventing it from memorizing noise or specific \\nexample s.  \\nEarly stopping is a regularization technique commonly used in training neural networks to \\nprevent overfitting. Overfitting occurs when a model becomes too specialized to the training \\ndata and performs poorly on new, unseen data.  \\nDuring the training pr ocess, early stopping involves continuously monitoring the model\\'s \\nperformance on a separate validation set. This set is distinct from the training set and serves \\nas a proxy for unseen data.  \\nAs training progresses, the model\\'s performance on the validation  set is evaluated at regular \\nintervals. The performance metric could be accuracy, loss, or any other relevant measure of \\nthe model\\'s performance.  \\nIf the model\\'s performance on the validation set starts to deteriorate or plateau, indicating that \\nit is no lo nger generalizing well to new data, the training process is halted. This means that \\nthe model is not further optimized or fine -tuned.  \\nBy stopping the training early, the model avoids excessive optimization that may cause it to \\nfit noise or specific example s in the training data. It helps strike a balance between capturing \\nmeaningful patterns and preventing overfitting.  \\nEarly stopping acts as a form of regularization by preventing the model from becoming too \\ncomplex and overly adapted to the training data. I t encourages the model to generalize well to \\nnew, unseen data.  \\nIt\\'s important to note that the choice of when to stop the training is based on the validation set \\nperformance, not the training set. This ensures that the model\\'s performance is assessed on \\ndata that it hasn\\'t seen during training, providing a more reliable estimate of its generalization \\nability.  5 \\n In summary, early stopping is a regularization technique that monitors the model\\'s \\nperformance on a validation set during training. It stops the train ing process when the model\\'s \\nperformance on the validation set starts to deteriorate, preventing overfitting and promoting \\nbetter generalization to new, unseen data.  \\nV. Bagging and Ensemble Methods:  Bagging (bootstrap aggregating) and ensemble \\nmethods are tec hniques that combine multiple models to improve the overall \\npredictive performance . Bagging  involves training multiple models on different \\nsubsets of the training data, typically through bootstrapping (sampling with \\nreplacement).  The predictions of these models are then aggregated, often by taking a \\nsimple average, to obtain the final prediction. Ensemble methods , such as random \\nforests or gradient boosting, go beyond bagging by combining multiple models in a \\nmore sophisticated way , often using weighted averaging or sequentially updating the \\nmodels based on their performance.  \\n\\uf0b7 Bagging (Bootstrap Aggregating):  Bagging, short for bootstrap aggregating  is a \\ntechnique used to improve the predictive performance of machine learning models.  It \\ninvolves training multiple models on different subsets of the training data and \\ncombining their predictions to obtain a final prediction.  \\nThe process of bagging starts by creating multiple subsets of the training data through a \\nprocess called bootstrap ping. Bootstrapping involves randomly sampling the training data \\nwith replacement, which means that each subset can contain duplicate instances from the \\noriginal data. By sampling with replacement, some instances may appear multiple times in a \\nsubset, whil e others may be left out. This random sampling process allows for the creation of \\ndiverse subsets that capture different aspects of the data.  \\nOnce the subsets are created, a separate model is trained on each subset using the same \\nlearning algorithm. This m eans that each model is exposed to a slightly different perspective \\nof the data due to the variations introduced by bootstrapping. As a result, the models are \\nlikely to have different strengths and weaknesses.  \\nTo make predictions, each individual model is applied to the test data, resulting in a set of \\npredictions. These predictions are then combined by aggregating them, often by taking a \\nsimple average. For regression problems, the average of the predicted values is taken, while \\nfor classification problems , the predicted probabilities or class labels may be combined \\nthrough voting or averaging.  6 \\n The main advantage of bagging is that it reduces the variance of the model\\'s predictions by \\naveraging the predictions of multiple models trained on different subsets  of the data. This \\nhelps to mitigate the impact of outliers or noise in the training data and leads to more stable \\nand reliable predictions. Additionally, bagging allows for parallelization since each model \\ncan be trained independently.  \\n\\uf0b7 Ensemble Methods:  Ensemble methods build upon the idea of bagging and go \\nbeyond simple averaging of predictions. Ensemble methods combine multiple models \\nin a more sophisticated way to further improve predictive performance.  \\n1. Random Forests  is one popular ensemble method that combines the ideas of bagging \\nand decision trees. In a random forest, multiple decision trees are trained on \\ndifferent bootstrapped subsets of the data.  However, in addition to using different \\nsubsets of the data, rando m forests also introduce randomness in the feature selection \\nprocess during tree construction. At each split in a decision tree, a random subset of \\nfeatures is considered, reducing the correlation between the trees and enhancing the \\ndiversity of the ensemb le. \\nThe final prediction of a random forest is obtained by aggregating the predictions of all the \\ntrees, typically through a majority vote (for classification) or averaging (for regression).  \\nRandom forests are known for their robustness, ability to handle high-dimensional data, and \\nresistance to overfitting.  \\n2. Gradient boosting , which builds models sequentially, with each new model \\ncorrecting the mistakes made by the previous models. Gradient boosting starts by \\ntraining an initial model, such as a decision tr ee, on the training data. The subsequent \\nmodels are then trained to predict the residuals (the differences between the observed \\nand predicted values) of the previous models. The predictions of all the models are \\nsummed up to obtain the final prediction.  \\nIn gradient boosting, each model is trained using a weighted version of the training data, \\nwhere the weights are based on the performance of the previous models.  This approach \\ngives more emphasis to the instances that were poorly predicted in previous iterat ions, \\nallowing the model to focus on the harder -to-predict cases. Gradient boosting is known for its \\nability to handle complex relationships and achieve high predictive accuracy.  7 \\n Ensemble methods, such as random forests and gradient boosting, leverage the collective \\nknowledge and diversity of multiple models to achieve better predictive performance \\ncompared to individual models. They provide a powerful framework for handling a wide \\nrange of machine learning tasks and have been successfully applied in variou s domains.  \\nVI. Dropouts:  Dropout is a regularization technique specific to neural networks. During \\ntraining, dropout randomly sets a fraction of the neurons in a layer to zero , effectively \\n\"dropping them out\" of the network for that particular forward and backward pass. \\nThis stochastic dropout process helps prevent overfitting and reduces the reliance of \\nthe network on specific neurons. By introducing noise and encouraging the network to \\nlearn more robust representations, dropout improves the generalization  performance \\nof neural networks. During inference, the dropout is typically turned off or scaled to \\nobtain a more accurate prediction.  \\nDropout is a regularization technique used in neural networks to prevent overfitting and \\nimprove generalization performan ce. It addresses the problem of neural networks relying too \\nheavily on specific neurons or learning redundant features from the training data.  \\nDuring the training process, dropout randomly sets a fraction of the neurons in a layer to zero, \\neffectively \"dro pping them out\" for that particular forward and backward pass. The dropout \\nrate determines the probability of a neuron being dropped out, typically ranging from 0.2 to \\n0.5. \\nBy dropping out neurons, dropout introduces noise and randomness into the network. This \\nstochastic process forces the network to learn more robust representations by preventing co -\\nadaptation of neurons. In other words, dropout discourages the network from relying on \\nspecific neurons to make accurate predictions and encourages the learnin g of more \\ndistributed and diverse features.  \\nThe impact of dropout is that the network becomes less sensitive to the presence of any \\nindividual neuron. It forces the network to rely on the collective knowledge of a diverse \\nset of neurons for making predicti ons, as different subsets of neurons are dropped out \\nin each training iteration.  This effect can be seen as an ensemble of multiple subnetworks \\nthat share parameters. Dropout effectively approximates the training of an exponential \\nnumber of thinned network s with different subsets of neurons.  8 \\n During inference or the prediction phase, dropout is typically turned off or scaled down. This \\nis done to obtain more accurate and deterministic predictions from the network. When \\ndropout is turned off, all the neurons are active, and the weights are scaled by the dropout rate \\nto compensate for the larger number of active neurons. This scaling ensures that the total \\ninput to each neuron remains approximately the same as during training, maintaining the \\nexpected activatio ns. \\nThe benefits of dropout  include regularizing the network, reducing overfitting, and \\nimproving generalization performance. By randomly dropping out neurons, dropout acts as a \\nform of noise injection during training, which helps to prevent the network fr om memorizing \\nthe training data too closely. It encourages the network to learn more robust and \\nrepresentative features that are applicable to unseen data.  \\nDropout has been shown to be particularly effective in deep neural networks, where \\noverfitting can b e a significant concern. It has been widely adopted in various neural network \\narchitectures and has contributed to the advancement of deep learning models.  \\nIn summary, dropout is a regularization technique that improves the generalization \\nperformance of ne ural networks by randomly dropping out neurons during training. It \\nreduces overfitting, encourages the learning of more robust features, and approximates \\nan ensemble of subnetworks.  During inference, dropout is usually turned off or scaled down \\nto obtain m ore accurate predictions.  \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token = ASTRA_DB_APPLICATION_TOKEN, database_id = ASTRA_DB_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puF2BSBB8-Au",
        "outputId": "5869330d-c695-41d6-bb0b-b1e837e161de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for aba867ca-e7a3-4f67-bd60-3225bf900631-us-east-1.db.astra.datastax.com:29042:a8f70534-3a0e-4471-909c-1d8babbd2bae. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for aba867ca-e7a3-4f67-bd60-3225bf900631-us-east-1.db.astra.datastax.com:29042:a8f70534-3a0e-4471-909c-1d8babbd2bae. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(134523074756512) aba867ca-e7a3-4f67-bd60-3225bf900631-us-east-1.db.astra.datastax.com:29042:a8f70534-3a0e-4471-909c-1d8babbd2bae> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for aba867ca-e7a3-4f67-bd60-3225bf900631-us-east-1.db.astra.datastax.com:29042:a8f70534-3a0e-4471-909c-1d8babbd2bae. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key = OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key = OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "8u9JFvzP9Qp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding = embedding,\n",
        "    table_name = 'QA_mini_demo',\n",
        "    session = None,\n",
        "    keyspace = None\n",
        ")"
      ],
      "metadata": {
        "id": "ySGHGA8e9fbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "_v1H-QeY-Rxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLD4zyTi-9tJ",
        "outputId": "205e2ea8-9ca9-4384-e561-9511bfd63bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"1 \\n UNIT -3: Parameter Norm Penalties, Data set augmentation, Noise Robustness, Early \\nstopping, Bagging and other Ensemble methods, Dropouts.  \\nI. Parameter Norm Penalties: Parameter norm penalties, also known as regularization \\ntechniques, are methods used to prevent overfitting and improve the generalization \\nperformance of machine learning models. These penalties add a term to the loss \\nfunction during training that encourages the model's weights to stay small or have a \\nsparse distribution. By constraining the weights, parameter norm penalties help \\nprevent the model from fitting the noise in the training data and promote more robust \\nand simpler solutions. Examples of parameter norm penalties include L1 \\nregularization (Lasso) and L2 regularization (Ridge regressi on).\",\n",
              " \"and simpler solutions. Examples of parameter norm penalties include L1 \\nregularization (Lasso) and L2 regularization (Ridge regressi on). \\nParameter norm penalties, such as L1 and L2 regularization, are techniques used in machine \\nlearning to prevent overfitting and improve the performance of models.  \\nOverfitting occurs when a model becomes too specialized to the training data and perform s \\npoorly on new, unseen data.  \\nParameter norm penalties add an extra term to the loss function during training, encouraging \\nthe model's weights to stay small or have a sparse distribution.  \\nBy constraining the weights, these penalties prevent the model from fitting noise in the \\ntraining data, leading to more robust and reliable solutions.\",\n",
              " 'By constraining the weights, these penalties prevent the model from fitting noise in the \\ntraining data, leading to more robust and reliable solutions.  \\nL1 regularization, also known as Lasso regularization, adds the absolute values of the weights \\nto the loss function. This encourages the model to have sparse weights, meanin g it will \\nprioritize some features while disregarding others.  \\nL2 regularization, also called Ridge regression, adds the squared values of the weights to the \\nloss function. This penalty prefers small weights and discourages the model from relying \\nheavily on  a few features.  \\nBoth L1 and L2 regularization techniques help simplify the model, promoting solutions that \\nare less prone to overfitting and have better generalization performance on unseen data.',\n",
              " \"Both L1 and L2 regularization techniques help simplify the model, promoting solutions that \\nare less prone to overfitting and have better generalization performance on unseen data.  \\nIn summary, parameter norm penalties are regularization tec hniques that control the size and \\ndistribution of a model's weights, preventing overfitting and improving the model's ability to \\ngeneralize to new data.  2 \\n II. Data Set Augmentation:  Data set augmentation is a technique used  to increase the \\nsize and diversity of the training data by applying various transformations or \\nperturbations to the existing data.  This technique can help improve the generalization \\nperformance of models, especially in situations where the available training data is\",\n",
              " 'perturbations to the existing data.  This technique can help improve the generalization \\nperformance of models, especially in situations where the available training data is \\nlimited. Data set augmen tation methods include rotation, translation, scaling, flipping, \\nadding noise, and introducing small variations to the data samples.  By augmenting the \\ndata set, the model becomes more robust to variations and can learn more generalized \\npatterns.  \\nData set augmentation is a method used to make training data larger and more diverse.  \\nBy applying different transformations or changes to the existing data, data set augmentation \\ncan improve the performance of models, especially when there is limited training data \\navailable.',\n",
              " 'By applying different transformations or changes to the existing data, data set augmentation \\ncan improve the performance of models, especially when there is limited training data \\navailable.  \\nVarious transformations can be used for data set augmentation, such as rotating, translating, \\nscaling, flipping, adding noise, or making small variations to the data samples.  \\nWhen we augment the data set, we introduce more variations and increas e the robustness of \\nthe model to different patterns and scenarios.  \\nFor example, by rotating an image slightly or flipping it horizontally, we can create new \\nsamples that still represent the same object or concept.  \\nAdding noise to the data, such as random p ixel variations, can simulate real -world scenarios',\n",
              " 'samples that still represent the same object or concept.  \\nAdding noise to the data, such as random p ixel variations, can simulate real -world scenarios \\nand make the model more resilient to noise in the input data.  \\nBy augmenting the data set, the model can learn from a broader range of examples and \\ngeneralize better to unseen data.  \\nIn summary, data set aug mentation involves applying transformations or perturbations to \\nexisting data to create a larger and more diverse training set. This helps the model become \\nmore robust and capable of generalizing to different patterns and variations.  \\nIII. Noise Robustness:  Nois e robustness refers to the ability of a machine learning model \\nto handle noisy or corrupted input data . In real -world scenarios, data can be corrupted',\n",
              " \"III. Noise Robustness:  Nois e robustness refers to the ability of a machine learning model \\nto handle noisy or corrupted input data . In real -world scenarios, data can be corrupted \\nby various sources of noise, such as sensor noise, measurement errors, or \\nperturbations. Models that are robust to noise can still make accurate predictions or 3 \\n classifications despite the presence of noisy data. Techniques for improving noise \\nrobustness include data preprocessing (e.g., denoising algorithms), feature selection or \\nextraction, robust statistica l estimators, and regularized models.  \\nNoise robustness in machine learning refers to a model's capability to handle input data that is \\ncorrupted or contains noise. In real -world situations, data can be affected by different sources\",\n",
              " \"Noise robustness in machine learning refers to a model's capability to handle input data that is \\ncorrupted or contains noise. In real -world situations, data can be affected by different sources \\nof noise, like sensor inaccuracies, measurement errors, or disturbances in the environment.  \\nA noise -robust model can still provide accurate predictions or classifications even when faced \\nwith such noisy data. This is important because noise can distort the true underlying patterns \\nin the data, making it challenging for models to extract meaningful information.  \\nThere are several techniques that can be employed to enhance noise robustness:  \\n1. Data Preprocessing:  One approach is to apply denoising algorithms or filters to\",\n",
              " \"There are several techniques that can be employed to enhance noise robustness:  \\n1. Data Preprocessing:  One approach is to apply denoising algorithms or filters to \\nremove or reduce noise from the input data before feeding it to the model. These \\nalgorithms can help in separating the noise from the actual signal, enhancing the \\nmodel's ability to make accurate  predictions.  \\n2. Feature Selection or Extraction:  Another technique involves selecting or extracting \\nfeatures that are less sensitive to noise. By focusing on robust features that capture \\nessential patterns in the data while being less affected by noise, the model can \\nimprove its noise robustness.  \\n3. Robust Statistical Estimators:  Instead of relying on traditional statistical estimators\",\n",
              " \"improve its noise robustness.  \\n3. Robust Statistical Estimators:  Instead of relying on traditional statistical estimators \\nthat assume data follows a specific distribution, robust statistical estimators are \\ndesigned to be more resistant to outliers an d noisy data. These estimators provide \\nmore reliable estimates and can be utilized in building noise -robust models.  \\n4. Regularized Models:  Regularization techniques, such as L1 or L2 regularization, can \\nalso contribute to noise robustness. By adding penalties  to the model's loss function, \\nregularization encourages simpler and more robust solutions that are less affected by \\nnoise in the training data.  \\nBy employing these techniques, noise robustness can be improved, enabling machine\",\n",
              " \"regularization encourages simpler and more robust solutions that are less affected by \\nnoise in the training data.  \\nBy employing these techniques, noise robustness can be improved, enabling machine \\nlearning models to handle noi sy or corrupted data more effectively. This ensures that the \\nmodels can still make accurate predictions or classifications, even in real -world scenarios \\nwhere noise is present.  4 \\n IV. Early Stopping:  Early stopping is a regularization technique used during the t raining \\nof neural networks to prevent overfitting.  It involves monitoring the model's \\nperformance on a validation set during training and stopping the training process \\nwhen the performance on the validation set starts to deteriorate. By stopping the\",\n",
              " \"performance on a validation set during training and stopping the training process \\nwhen the performance on the validation set starts to deteriorate. By stopping the \\ntraini ng early, the model avoids further optimization that may lead to overfitting the \\ntraining data. Early stopping helps find a balance between training the model enough \\nto capture meaningful patterns and preventing it from memorizing noise or specific \\nexample s.  \\nEarly stopping is a regularization technique commonly used in training neural networks to \\nprevent overfitting. Overfitting occurs when a model becomes too specialized to the training \\ndata and performs poorly on new, unseen data.  \\nDuring the training pr ocess, early stopping involves continuously monitoring the model's\",\n",
              " \"data and performs poorly on new, unseen data.  \\nDuring the training pr ocess, early stopping involves continuously monitoring the model's \\nperformance on a separate validation set. This set is distinct from the training set and serves \\nas a proxy for unseen data.  \\nAs training progresses, the model's performance on the validation  set is evaluated at regular \\nintervals. The performance metric could be accuracy, loss, or any other relevant measure of \\nthe model's performance.  \\nIf the model's performance on the validation set starts to deteriorate or plateau, indicating that \\nit is no lo nger generalizing well to new data, the training process is halted. This means that \\nthe model is not further optimized or fine -tuned.\",\n",
              " \"it is no lo nger generalizing well to new data, the training process is halted. This means that \\nthe model is not further optimized or fine -tuned.  \\nBy stopping the training early, the model avoids excessive optimization that may cause it to \\nfit noise or specific example s in the training data. It helps strike a balance between capturing \\nmeaningful patterns and preventing overfitting.  \\nEarly stopping acts as a form of regularization by preventing the model from becoming too \\ncomplex and overly adapted to the training data. I t encourages the model to generalize well to \\nnew, unseen data.  \\nIt's important to note that the choice of when to stop the training is based on the validation set \\nperformance, not the training set. This ensures that the model's performance is assessed on\",\n",
              " \"It's important to note that the choice of when to stop the training is based on the validation set \\nperformance, not the training set. This ensures that the model's performance is assessed on \\ndata that it hasn't seen during training, providing a more reliable estimate of its generalization \\nability.  5 \\n In summary, early stopping is a regularization technique that monitors the model's \\nperformance on a validation set during training. It stops the train ing process when the model's \\nperformance on the validation set starts to deteriorate, preventing overfitting and promoting \\nbetter generalization to new, unseen data.  \\nV. Bagging and Ensemble Methods:  Bagging (bootstrap aggregating) and ensemble \\nmethods are tec hniques that combine multiple models to improve the overall\",\n",
              " 'V. Bagging and Ensemble Methods:  Bagging (bootstrap aggregating) and ensemble \\nmethods are tec hniques that combine multiple models to improve the overall \\npredictive performance . Bagging  involves training multiple models on different \\nsubsets of the training data, typically through bootstrapping (sampling with \\nreplacement).  The predictions of these models are then aggregated, often by taking a \\nsimple average, to obtain the final prediction. Ensemble methods , such as random \\nforests or gradient boosting, go beyond bagging by combining multiple models in a \\nmore sophisticated way , often using weighted averaging or sequentially updating the \\nmodels based on their performance.  \\n\\uf0b7 Bagging (Bootstrap Aggregating):  Bagging, short for bootstrap aggregating  is a',\n",
              " 'models based on their performance.  \\n\\uf0b7 Bagging (Bootstrap Aggregating):  Bagging, short for bootstrap aggregating  is a \\ntechnique used to improve the predictive performance of machine learning models.  It \\ninvolves training multiple models on different subsets of the training data and \\ncombining their predictions to obtain a final prediction.  \\nThe process of bagging starts by creating multiple subsets of the training data through a \\nprocess called bootstrap ping. Bootstrapping involves randomly sampling the training data \\nwith replacement, which means that each subset can contain duplicate instances from the \\noriginal data. By sampling with replacement, some instances may appear multiple times in a',\n",
              " 'with replacement, which means that each subset can contain duplicate instances from the \\noriginal data. By sampling with replacement, some instances may appear multiple times in a \\nsubset, whil e others may be left out. This random sampling process allows for the creation of \\ndiverse subsets that capture different aspects of the data.  \\nOnce the subsets are created, a separate model is trained on each subset using the same \\nlearning algorithm. This m eans that each model is exposed to a slightly different perspective \\nof the data due to the variations introduced by bootstrapping. As a result, the models are \\nlikely to have different strengths and weaknesses.  \\nTo make predictions, each individual model is applied to the test data, resulting in a set of',\n",
              " \"likely to have different strengths and weaknesses.  \\nTo make predictions, each individual model is applied to the test data, resulting in a set of \\npredictions. These predictions are then combined by aggregating them, often by taking a \\nsimple average. For regression problems, the average of the predicted values is taken, while \\nfor classification problems , the predicted probabilities or class labels may be combined \\nthrough voting or averaging.  6 \\n The main advantage of bagging is that it reduces the variance of the model's predictions by \\naveraging the predictions of multiple models trained on different subsets  of the data. This \\nhelps to mitigate the impact of outliers or noise in the training data and leads to more stable\",\n",
              " 'averaging the predictions of multiple models trained on different subsets  of the data. This \\nhelps to mitigate the impact of outliers or noise in the training data and leads to more stable \\nand reliable predictions. Additionally, bagging allows for parallelization since each model \\ncan be trained independently.  \\n\\uf0b7 Ensemble Methods:  Ensemble methods build upon the idea of bagging and go \\nbeyond simple averaging of predictions. Ensemble methods combine multiple models \\nin a more sophisticated way to further improve predictive performance.  \\n1. Random Forests  is one popular ensemble method that combines the ideas of bagging \\nand decision trees. In a random forest, multiple decision trees are trained on \\ndifferent bootstrapped subsets of the data.  However, in addition to using different',\n",
              " 'and decision trees. In a random forest, multiple decision trees are trained on \\ndifferent bootstrapped subsets of the data.  However, in addition to using different \\nsubsets of the data, rando m forests also introduce randomness in the feature selection \\nprocess during tree construction. At each split in a decision tree, a random subset of \\nfeatures is considered, reducing the correlation between the trees and enhancing the \\ndiversity of the ensemb le. \\nThe final prediction of a random forest is obtained by aggregating the predictions of all the \\ntrees, typically through a majority vote (for classification) or averaging (for regression).  \\nRandom forests are known for their robustness, ability to handle high-dimensional data, and \\nresistance to overfitting.',\n",
              " 'Random forests are known for their robustness, ability to handle high-dimensional data, and \\nresistance to overfitting.  \\n2. Gradient boosting , which builds models sequentially, with each new model \\ncorrecting the mistakes made by the previous models. Gradient boosting starts by \\ntraining an initial model, such as a decision tr ee, on the training data. The subsequent \\nmodels are then trained to predict the residuals (the differences between the observed \\nand predicted values) of the previous models. The predictions of all the models are \\nsummed up to obtain the final prediction.  \\nIn gradient boosting, each model is trained using a weighted version of the training data, \\nwhere the weights are based on the performance of the previous models.  This approach',\n",
              " 'In gradient boosting, each model is trained using a weighted version of the training data, \\nwhere the weights are based on the performance of the previous models.  This approach \\ngives more emphasis to the instances that were poorly predicted in previous iterat ions, \\nallowing the model to focus on the harder -to-predict cases. Gradient boosting is known for its \\nability to handle complex relationships and achieve high predictive accuracy.  7 \\n Ensemble methods, such as random forests and gradient boosting, leverage the collective \\nknowledge and diversity of multiple models to achieve better predictive performance \\ncompared to individual models. They provide a powerful framework for handling a wide \\nrange of machine learning tasks and have been successfully applied in variou s domains.',\n",
              " 'compared to individual models. They provide a powerful framework for handling a wide \\nrange of machine learning tasks and have been successfully applied in variou s domains.  \\nVI. Dropouts:  Dropout is a regularization technique specific to neural networks. During \\ntraining, dropout randomly sets a fraction of the neurons in a layer to zero , effectively \\n\"dropping them out\" of the network for that particular forward and backward pass. \\nThis stochastic dropout process helps prevent overfitting and reduces the reliance of \\nthe network on specific neurons. By introducing noise and encouraging the network to \\nlearn more robust representations, dropout improves the generalization  performance \\nof neural networks. During inference, the dropout is typically turned off or scaled to']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_texts(texts[:25])\n",
        "\n",
        "print('Inserted %i headlines.'% len(texts[:25]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore = astra_vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doI2mUQu_IPn",
        "outputId": "1e5f0514-4403-4c16-d86c-4214bac906ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 25 headlines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text = input('\\nEnter your question (or type \\'quit\\' to exit)').strip()\n",
        "  else:\n",
        "    query_text = input('\\What\\'s your next question(or type \\'quit\\' to exit)').strip()\n",
        "\n",
        "  if query_text.lower() == 'quit':\n",
        "    break\n",
        "\n",
        "  if query_text == '':\n",
        "    continue\n",
        "\n",
        "  first_question = False\n",
        "\n",
        "  print('\\nQUESTION: \"%s\"'%query_text)\n",
        "\n",
        "  answer = astra_vector_index.query(query_text, llm = llm).strip()\n",
        "  print('Answer: \"%s\"'%answer)\n",
        "\n",
        "  print('FIRST DOCUMENT BY RELEVANCE:')\n",
        "  for doc, score in astra_vector_store.similarity_search_with_score(query_text, k = 4):\n",
        "    print('     [%0.4f] \"%s  ...\"'% (score, doc.page_content[:100]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uitydAUt_mGe",
        "outputId": "3d829396-1195-4132-d5c3-2f3e19d3f9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit)quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYwnF-SNCJ0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}